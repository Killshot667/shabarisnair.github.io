---
title: "Sprinklr"
collection: experiences
category: professional
excerpt: |
  <div style='display: flex; justify-content: space-between; align-items: center;'>
  <span><strong>AI Product Engineer - Voice Team</strong></span>
  <span>July 2023 - Present</span>
  </div>

  - Worked on optimization and maintenance of deployment pipelines, as well as research in the domains of Text-to-Speech (TTS) and Automatic Speech Recognition (ASR) services.
  - Owned the bulk of Text-to-Speech (TTS) client deployments (70+), including their maintenance, bug fixes, and alerts
  - Developed a novel zero-shot prompting-based technique for contextual biasing in Whisper, improving WER over the baseline by 45.6% for rare words and 60.8% for out-of-vocab words, with generalization to unseen languages as well. Results published in SLT 2024
  - Spearheaded the ASR latency optimization track, conducting in-depth study and implementing techniques like quantization, speculative decoding, flash attention, and specialized inference engines , achieving a 3x latency improvement

  <div style="display: flex; justify-content: space-between; align-items: center;">
    <span><strong>AI Product Engineer Intern</strong></span>
    <span>May 2022 - July 2022</span>
  </div>

  - Performed independent research on the topic of Structured Sentiment Analysis. [[refer]](https://aclanthology.org/2022.semeval-1.180.pdf)
  - Implemented modular (splitting the main task into sub tasks) and dependency-graph (end-to-end model) based models
  - Optimized the dependency-graoh based model using LLMs like XLM-RoBERTa for better word embeddings and data augmentation, leading to a 15% average improvement over the baseline across 7 datasets in 5 languages
  - Adapted the model to work for Asian languages such as Mandarin, as well as for sarcastic texts via Multitask learning

# permalink: /experiences/work-2
# date: 2022-12-03
# venue: "Briefings in Bioinformatics'23"
# status: "Published"
# slidesurl: 'http://academicpages.github.io/files/slides2.pdf'
# paperurl: 'https://killshot667.github.io/shabarisnair.github.io/files/concept.pdf'
# citation: 'Vandana Bharti, Shabari S Nair, Akshat Jain, Kaushal Kumar Shukla, Bhaskar Biswas'
---
  <div style='display: flex; justify-content: space-between; align-items: center;'>
  <span><strong>AI Product Engineer - Voice Team</strong></span>
  <span>July 2023 - Present</span>
  </div>

  - Worked on optimization and maintenance of deployment pipelines, as well as research in the domains of Text-to-Speech (TTS) and Automatic Speech Recognition (ASR) services.
  - Owned the bulk of Text-to-Speech (TTS) client deployments (70+), including their maintenance, bug fixes, and alerts
  - Developed a novel zero-shot prompting-based technique for contextual biasing in Whisper, improving WER over the baseline by 45.6% for rare words and 60.8% for out-of-vocab words, with generalization to unseen languages as well. Results published in SLT 2024
  - Spearheaded the ASR latency optimization track, conducting in-depth study and implementing techniques like quantization, speculative decoding, flash attention, and specialized inference engines , achieving a 3x latency improvement

  <div style="display: flex; justify-content: space-between; align-items: center;">
    <span><strong>AI Product Engineer Intern</strong></span>
    <span>May 2022 - July 2022</span>
  </div>

  - Performed independent research on the topic of Structured Sentiment Analysis. [[refer]](https://aclanthology.org/2022.semeval-1.180.pdf)
  - Implemented modular (splitting the main task into sub tasks) and dependency-graph (end-to-end model) based models
  - Optimized the dependency-graoh based model using LLMs like XLM-RoBERTa for better word embeddings and data augmentation, leading to a 15% average improvement over the baseline across 7 datasets in 5 languages
  - Adapted the model to work for Asian languages such as Mandarin, as well as for sarcastic texts via Multitask learning